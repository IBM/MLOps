{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7db81b2-a955-436b-a4a9-c4e31ff1351e",
    "tags": []
   },
   "source": [
    "## Training Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5c3939e-aa16-472f-9213-66e415d7f94a"
   },
   "source": [
    "### The following cell is a way to get the utility script required for this notebook. \n",
    "Since IBM CPD SaaS doesn't have a filesystem, this is the only reliable way to get scripts on the cloud environment.\n",
    "\n",
    "```\n",
    "!rm -rf MLOps-CPD && git clone --quiet -b master https://github.com/IBM/MLOps-CPD.git\n",
    "```\n",
    "\n",
    "⚠️ Run the following cells only if you are executing on IBM CPD SaaS.\n",
    "\n",
    "this is a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fc041cf-55e8-4ce4-9ee0-a7f4bac3af11",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "581de62c-b62a-48bf-9105-efac5dd8c45f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: ibm_watson_machine_learning in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (1.0.308)\n",
      "Requirement already satisfied: ibm_watson_studio_pipelines in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (0.2.12)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (3.3.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (1.23.5)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (1.10.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (2.8.4)\n",
      "Requirement already satisfied: future in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (4.65.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from hyperopt) (2.2.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (2.31.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (1.26.15)\n",
      "Requirement already satisfied: pandas<1.6.0,>=0.24.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (1.5.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (2023.5.7)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (0.3.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (0.8.10)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (4.13.0)\n",
      "Requirement already satisfied: ibm-cos-sdk<2.14.0,>=2.12.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_machine_learning) (2.12.0)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core>=3.11.3 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_studio_pipelines) (3.16.5)\n",
      "Requirement already satisfied: attrs>=21.2.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_studio_pipelines) (22.1.0)\n",
      "Requirement already satisfied: responses>=0.13.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_studio_pipelines) (0.23.3)\n",
      "Requirement already satisfied: pytest>=6.2.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_studio_pipelines) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm_watson_studio_pipelines) (4.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from lightgbm) (0.38.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from lightgbm) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm-cloud-sdk-core>=3.11.3->ibm_watson_studio_pipelines) (2.8.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.4.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm-cloud-sdk-core>=3.11.3->ibm_watson_studio_pipelines) (2.4.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.12.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm_watson_machine_learning) (2.12.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.12.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm_watson_machine_learning) (2.12.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.10.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from ibm-cos-sdk<2.14.0,>=2.12.0->ibm_watson_machine_learning) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pandas<1.6.0,>=0.24.2->ibm_watson_machine_learning) (2022.7)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pytest>=6.2.5->ibm_watson_studio_pipelines) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pytest>=6.2.5->ibm_watson_studio_pipelines) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pytest>=6.2.5->ibm_watson_studio_pipelines) (1.11.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from pytest>=6.2.5->ibm_watson_studio_pipelines) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->ibm_watson_machine_learning) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from requests->ibm_watson_machine_learning) (3.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from responses>=0.13.4->ibm_watson_studio_pipelines) (6.0)\n",
      "Requirement already satisfied: types-PyYAML in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from responses>=0.13.4->ibm_watson_studio_pipelines) (6.0.12.12)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from importlib-metadata->ibm_watson_machine_learning) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages (from packaging->ibm_watson_machine_learning) (3.0.9)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install hyperopt ibm_aigov_facts_client ibm_watson_machine_learning ibm_watson_studio_pipelines lightgbm # temporarly removing fact_sheets due to installation issues\n",
    "!pip install hyperopt  ibm_watson_machine_learning ibm_watson_studio_pipelines lightgbm python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54418317-5b6f-4d8f-8f01-3f8fcb012975",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from ibm_botocore.client import Config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,f1_score,auc,roc_curve,accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "# from ibm_aigov_facts_client import AIGovFactsClient, CloudPakforDataConfig #removing temporarly due to installation issues\n",
    "from ibm_watson_studio_pipelines import WSPipelines\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "import warnings\n",
    "import os, types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ibm_boto3\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import exists\n",
    "# from utils import fs_utils,catalog_utils #removing temporarly due to installation issues\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import seaborn  as sns\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Optional pluging skipped\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ec9f3a1-7843-4a56-be1f-27321cc488aa"
   },
   "source": [
    "## Pipeline Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vars_and_utils as vars_and_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6Ik90clNOcWRuQVAwYi1EWThuU3lRc25CbEMyc3N1X0dCcGdLODI2ZklELWMifQ.eyJ1aWQiOiIxMDAwMzMxMDE4IiwidXNlcm5hbWUiOiJtamVzY2giLCJyb2xlIjoiVXNlciIsInBlcm1pc3Npb25zIjpbImFjY2Vzc19jYXRhbG9nIiwidmlld19nb3Zlcm5hbmNlX2FydGlmYWN0cyIsIm1hbmFnZV9jYXRhbG9nIiwiY3JlYXRlX3NwYWNlIiwibWFuYWdlX3NwYWNlIiwibW9uaXRvcl9zcGFjZSIsIm1hbmFnZV9kaXNjb3ZlcnkiLCJnbG9zc2FyeV9hZG1pbiIsImF1dGhvcl9nb3Zlcm5hbmNlX2FydGlmYWN0cyIsIm1hbmFnZV9nbG9zc2FyeSIsIm1hbmFnZV9jYXRlZ29yaWVzIiwiYWNjZXNzX2RhdGFfcXVhbGl0eV9hc3NldF90eXBlcyIsImNyZWF0ZV9wcm9qZWN0IiwibWFuYWdlX3Byb2plY3QiLCJtb25pdG9yX3Byb2plY3QiLCJ2aWV3X3BsYXRmb3JtX2hlYWx0aCIsImFkZF92YXVsdHMiLCJtYW5hZ2VfdmF1bHRzX2FuZF9zZWNyZXRzIiwic2hhcmVfc2VjcmV0cyIsIm1hbmFnZV9nb3Zlcm5hbmNlX3dvcmtmbG93Il0sImdyb3VwcyI6WzEwMDAxLDEwMDAwXSwic3ViIjoibWplc2NoIiwiaXNzIjoiS05PWFNTTyIsImF1ZCI6IkRTWCIsImFwaV9yZXF1ZXN0Ijp0cnVlLCJpYXQiOjE2OTgxNDY0NjAsImV4cCI6NTI5ODE0Mjg2MH0.wmLcjNx0MBRCzk5U_LaUoN9uEHIQt5gXmgGnt9DU6qyiicP05suy9dyhnIw21kYtJGkZ2-rdQLO_2glSRb7lWHxkagJTmFIX4orE637nt7jo67ycKE2Vvap3rPcAHtnTRnv-ovdKPEru1sEQcqxnl04N1hw4ebANE5umJOAlok7lp9Uq1QCzs_TtMsYzU_bmyacjFKhhRYMHu2ZEH2ReI820H3s1gE1m30OS1RnfhfPW0tJR9qTLYkwI5tJR4nZ5srO355-X7ib70aYtSBBa_AyLCNY6Svp73xH4NC7qnLM1BqNtdQagBdCPv6o3CmGmnZ7sk7-1QRtUNQhPGZ51Xg'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"USER_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "766fc655-4aa3-4967-b341-9c3f19007e0d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook is running in a development enviroment\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "project_id= os.getenv('project_id')\n",
    "\n",
    "## REMOTE AUTH\n",
    "\n",
    "TOKEN = os.getenv(\"USER_ACCESS_TOKEN\")\n",
    "\n",
    "\n",
    "if os.getenv(\"running_in_production_pipeline\"):\n",
    "    running_in_production_pipeline = True\n",
    "    print(\"notebook is running in a production pipeline. This will cause some steps to be skipped\")\n",
    "else:\n",
    "    running_in_production_pipeline = False\n",
    "    print(\"notebook is running in a development enviroment\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e721c290-5509-412a-83ce-573935d14365"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5763f79b-74df-4c2d-9f63-e9a2f9718129",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def load_data_from_filesystem(path):\n",
    "#     \"\"\"\n",
    "#     Check existence of path in filesystem.\n",
    "#     If it does exist, loads csv via path\n",
    "#     If it does NOT exist, try to load data from Db2\n",
    "#     \"\"\"\n",
    "#     body = check_for_file_in_filesystem(path)\n",
    "#     if body:\n",
    "#         suffix = path[-3:]\n",
    "#         # Check whether path ends on csv\n",
    "#         if suffix == \"csv\":\n",
    "#             gcf_df = pd.read_csv(path)\n",
    "#         else:\n",
    "#             with open(path) as f:\n",
    "#                 gcf_df = pickle.load(f)\n",
    "\n",
    "#         return gcf_df\n",
    "#     else:\n",
    "#         print(\"\\n\")\n",
    "#         print(f\"{path} file/path is probably not in project. Loading File from MLOps COS Bucket.\")\n",
    "\n",
    "#         data_request = {\n",
    "#                 'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "#                 'interaction_properties': {\n",
    "#                     'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "#                 }\n",
    "#             }\n",
    "\n",
    "#         gcf_df = read_data_from_db2(data_request)\n",
    "#         return gcf_df\n",
    "\n",
    "\n",
    "# def read_data_from_db2(data_request):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     If load_data_from_filesystem fails, this method is executed.\n",
    "#     \"\"\"\n",
    "#     read_client = itcfs.get_flight_client()\n",
    "#     DB2_DATA_data_request = {\n",
    "#         'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "#         'interaction_properties': {\n",
    "#             'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     flightInfo = itcfs.get_flight_info(read_client, nb_data_request=data_request)\n",
    "\n",
    "#     df = itcfs.read_pandas_and_concat(read_client, flightInfo, timeout=240)\n",
    "#     return df\n",
    "\n",
    "# def save_data_in_filesystem(df,filename):\n",
    "#     \"\"\"\n",
    "#     Save Data in Filesystem\n",
    "\n",
    "#     Passed filename should involve path\n",
    "\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         if filename[-3:] == \"csv\":\n",
    "#             df.to_csv(filename,index=False)\n",
    "#             print(f\"File {filename} persisted successfully as csv\")\n",
    "#         else:\n",
    "#             with open(filename, 'wb') as f:\n",
    "#                 pickle.dump(df, f)\n",
    "#             print(f\"File {filename} pickled successfully\")\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f\"File serialization for {filename} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "189ac0c4-ddf1-4e51-b4f2-8478c1d8d4f2"
   },
   "source": [
    "## Load the Saved Transformer from IBM COS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_and_utils.pipeline_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97a6f8fa-3fa3-4310-84f7-435a544fdb42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = vars_and_utils.load_model(vars_and_utils.pipeline_path,vars_and_utils.pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22fd1435-a5a1-430a-8347-96498617dc05"
   },
   "source": [
    "## Instantiate FactSheets Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "601c230e-8608-46a4-a84b-d8c522fa699f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing temporarly due to installation issues\n",
    "\n",
    "# # Set-up Factsheets\n",
    "# cpd_creds = CloudPakforDataConfig(service_url=CPD_HOST, username=CPD_USERNAME, password=CPD_PASSWORD)\n",
    "    \n",
    "# if SPACE_ID is None:\n",
    "#     # Only of SPACE_ID is unavailble, fallback to PROJECT_ID\n",
    "#     if PROJECT_ID is None:\n",
    "#         # Neither SPACE_ID nor PROJECT_ID available\n",
    "#         pass\n",
    "#     else:\n",
    "#         # PROJECT_ID available\n",
    "#         deploy_to = 'project'\n",
    "#         try:\n",
    "#             # Create new experiment\n",
    "#             facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "#         except Exception as e:\n",
    "#             # Experiment already exists.. set as current experiment\n",
    "#             facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "#         else:\n",
    "#             print(e)\n",
    "# else:\n",
    "#     # SPACE_ID is available\n",
    "#     deploy_to = 'space'\n",
    "#     try:\n",
    "#         # Create new experiment\n",
    "#         facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "#     except Exception as e:\n",
    "#         # Experiment already exists.. set as current experiment\n",
    "#         facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "#     else:\n",
    "#         print(e)\n",
    "        \n",
    "# print(f\"Setting up Factsheets in {deploy_to}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "364b13f5-d3da-49c6-a07f-6edeace9f425"
   },
   "source": [
    "## Load Train Data and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c31c5352-efa4-40be-b1c0-20a11c092b62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = vars_and_utils.load_data(vars_and_utils.train_data_path)\n",
    "test_data = vars_and_utils.load_data(vars_and_utils.test_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f58d554-bb87-4ff4-843a-a496d82110a2"
   },
   "source": [
    "## Load train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "824e8d47-f471-431c-958f-2412802fd91f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_data['Risk']\n",
    "\n",
    "y_test = test_data['Risk']\n",
    "\n",
    "X_train = train_data.drop('Risk',axis=1)\n",
    "\n",
    "X_test = test_data.drop('Risk',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81fae16-dbb4-4d01-b538-b61f71d13c90"
   },
   "source": [
    "## Make validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3af40a2-1e07-4187-bfcb-c12b4b7208cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f79dd02f-22ad-468c-b6a2-235a342c0b48"
   },
   "source": [
    "## Instantiate a Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be29da66-e1b4-4802-94bd-c47255df3f3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_lgb = LGBMClassifier(learning_rate=0.09,max_depth=5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a305e5d9-4750-43f2-8484-85aff909c846"
   },
   "source": [
    "## Append the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "392e164d-948c-49be-adca-1f66b0a72752",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_step = ['model_lgb',model_lgb]\n",
    "pipeline.steps.append(estimator_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80f0fb0b-4131-4357-8bdf-3352f2acab94",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.steps[0][1].fit(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a1f5215-9233-4087-9315-439632632074"
   },
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0119280-a0e5-4e74-92cc-520352a85aba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"starting Model Training. This might take a while\")\n",
    "model_pipeline = pipeline.fit(X_tr,y_tr,model_lgb__verbose=5, model_lgb__eval_set=[(pipeline.steps[0][1].transform(X_val), y_val),(pipeline.steps[0][1].transform(X_tr), y_tr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06f4e2c0-8cf3-4752-8d50-f605014e9756",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import plot_metric\n",
    "plot_metric(pipeline.steps[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a765b3b-46df-4832-998d-f6aa88549744"
   },
   "source": [
    "## Log the Train and Val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae34e2b6-e9fd-401b-b1e2-8de878db2338",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = pipeline.steps[1][1].evals_result_['valid_0']\n",
    "train_loss = pipeline.steps[1][1].evals_result_['valid_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ea87773-790a-48fa-a4b1-5c8134747c9c"
   },
   "source": [
    "## Save train and val loss to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79517f43-a037-418d-88da-e872f5507d8b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss_path = os.path.join(vars_and_utils.data_path, 'val_loss.pkl')\n",
    "vars_and_utils.save_data_in_filesystem(val_loss, val_loss_path)\n",
    "\n",
    "train_loss_path = os.path.join(vars_and_utils.data_path, 'train_loss.pkl')\n",
    "vars_and_utils.save_data_in_filesystem(train_loss, train_loss_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c267c68-d6ab-4283-b157-27791c612f46"
   },
   "source": [
    "## Check if the files are copied in COS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6261ab04-eec2-4ba7-aeba-f4f1b2e0c355",
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_copied_in_cos = os.path.exists(val_loss_path) and os.path.exists(train_loss_path)\n",
    "files_copied_in_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6bb0c1d-b884-4a7a-bd50-e6fb0646be16"
   },
   "source": [
    "## Baseline Results of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "7804bdbb-2029-467e-8584-1a15bc90d10b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7175182385975962\n"
     ]
    }
   ],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "5d51f2fa-4deb-45c8-bad9-3bc489d5d739",
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/userfs/03-train_models.ipynb Cell 39\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1:5681/userfs/03-train_models.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m running_in_production_pipeline:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1:5681/userfs/03-train_models.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     cv \u001b[39m=\u001b[39m KFold(n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1:5681/userfs/03-train_models.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(cross_val_score(pipeline,X_train,y_train, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mroc_auc\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1:5681/userfs/03-train_models.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe Cross Validated AUC_ROC Score is \u001b[39m\u001b[39m{\u001b[39;00mscores\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B127.0.0.1:5681/userfs/03-train_models.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/Python-RT23.1-Premium/lib/python3.10/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not running_in_production_pipeline:\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scores = np.mean(cross_val_score(pipeline,X_train,y_train, cv=cv, n_jobs=-1,scoring='roc_auc'))\n",
    "    print(f\"The Cross Validated AUC_ROC Score is {scores}\")\n",
    "else:\n",
    "    print(\"Skipping KFold Validation in the production pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a28c746-bd73-4080-933a-9ae887c77b31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(pipeline.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69df87eb-9213-497b-987a-0cb95330e0fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cm = confusion_matrix(y_test,predictions)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in df_cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in df_cm.flatten()/np.sum(df_cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2,v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "try:\n",
    "    sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Seaborn missing, skipping optional heatmap plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b26c707b-15e5-4eb2-8fb8-8badb2f9ceba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print (\"Area Under Curve: %.2f\" %auc(fpr, tpr))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dac2a1f6-84c0-41c3-85ba-8bbdb574fd27"
   },
   "source": [
    "## Serialize Model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cbca9b7-f56f-4fef-98d7-dc9977ec9487",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(vars_and_utils.data_path, vars_and_utils.model_name+\".pkl\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ec81eb2-18be-4045-8265-dd57a269e6cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(model_path,'wb') as f:\n",
    "    pickle.dump(model_pipeline,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1ebe5c0-e8d9-47ed-94d8-2098f582d2b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skipping for now due to installation issues\n",
    "# cpd_ver = facts_client.get_cpd_version()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16bc9347-e945-4f0d-b108-1a12dd384667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "   \"token\": TOKEN,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n",
    "   \"version\": \"4.6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2bab309-8819-45ab-9baa-c796258c7704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wml_client = APIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b945b0d-2a2a-4415-bb1d-aad42e553958"
   },
   "source": [
    "## Save and Log Models in AI Factsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b814e00a-f777-4fb2-8f8b-58b17f6855c1"
   },
   "outputs": [],
   "source": [
    "# TODO: Rework this without helper scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9341e59f-1bea-4325-9371-e4317034e99e"
   },
   "source": [
    "## Save Params in WS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ac6de9b-1f91-4e95-a3c2-409c0b065ce6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {}\n",
    "train_params['auc_roc'] = float(auc(fpr, tpr))\n",
    "train_params['training_done'] = True\n",
    "train_params['model_name'] = vars_and_utils.model_name\n",
    "train_params['model_path'] = model_path\n",
    "train_params['deployment_name'] = vars_and_utils.deployment_name\n",
    "# train_params['model_id'] = model_id\n",
    "train_params['project_id'] = project_id if not None else None\n",
    "# train_params['model_pipeline'] = \"/home/wsuser/work/model_pipeline.pkl\"\n",
    "\n",
    "pipelines_client = WSPipelines.from_token(TOKEN)\n",
    "pipelines_client.store_results(train_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
