{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7db81b2-a955-436b-a4a9-c4e31ff1351e",
    "tags": []
   },
   "source": [
    "## Training Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup\n",
    "\n",
    "Some initial setup specific to running this notebook as part of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d17c866e-cab4-4283-bb67-d2f11d838a37"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#This environment variable is automatically set in WS Pipelines and are needed to access various services.\n",
    "TOKEN = os.getenv(\"USER_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a671034f-cb0b-4be3-8000-80e1791fa28b"
   },
   "outputs": [],
   "source": [
    "if os.getenv(\"running_in_production_pipeline\"):\n",
    "    running_in_production_pipeline = True\n",
    "    # If you want to run additional steps when deploying to production like reporting to external services, you can use this variable to trigger that\n",
    "    # It can also be used to skip steps that are only needed in development like plotting\n",
    "    print(\"notebook is running in a production pipeline!\")\n",
    "else:\n",
    "    running_in_production_pipeline = False\n",
    "    print(\"notebook is running in a development enviroment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54418317-5b6f-4d8f-8f01-3f8fcb012975",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from ibm_botocore.client import Config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,f1_score,auc,roc_curve,accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from ibm_watson_studio_pipelines import WSPipelines\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "import warnings\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ibm_boto3\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from os.path import exists\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import seaborn  as sns\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Optional pluging skipped\")\n",
    "    \n",
    "# Loading Variables and Utils from common python file\n",
    "import vars_and_utils as vars_and_utils\n",
    "    \n",
    "# some variables are stored in a .env file. Refer to readme for more information\n",
    "load_dotenv()\n",
    "project_id= os.getenv('PROJECT_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e721c290-5509-412a-83ce-573935d14365"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "189ac0c4-ddf1-4e51-b4f2-8478c1d8d4f2"
   },
   "source": [
    "## Load the Saved Transformer from IBM COS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3edea10-3dd6-4572-8b67-0caf36a9b7ca"
   },
   "outputs": [],
   "source": [
    "vars_and_utils.pipeline_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97a6f8fa-3fa3-4310-84f7-435a544fdb42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = vars_and_utils.load_model(vars_and_utils.pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22fd1435-a5a1-430a-8347-96498617dc05"
   },
   "source": [
    "## Instantiate FactSheets Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "601c230e-8608-46a4-a84b-d8c522fa699f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# removing temporarly due to installation issues\n",
    "\n",
    "# # Set-up Factsheets\n",
    "# cpd_creds = CloudPakforDataConfig(service_url=CPD_HOST, username=CPD_USERNAME, password=CPD_PASSWORD)\n",
    "    \n",
    "# if SPACE_ID is None:\n",
    "#     # Only of SPACE_ID is unavailble, fallback to PROJECT_ID\n",
    "#     if PROJECT_ID is None:\n",
    "#         # Neither SPACE_ID nor PROJECT_ID available\n",
    "#         pass\n",
    "#     else:\n",
    "#         # PROJECT_ID available\n",
    "#         deploy_to = 'project'\n",
    "#         try:\n",
    "#             # Create new experiment\n",
    "#             facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "#         except Exception as e:\n",
    "#             # Experiment already exists.. set as current experiment\n",
    "#             facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "#         else:\n",
    "#             print(e)\n",
    "# else:\n",
    "#     # SPACE_ID is available\n",
    "#     deploy_to = 'space'\n",
    "#     try:\n",
    "#         # Create new experiment\n",
    "#         facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "#     except Exception as e:\n",
    "#         # Experiment already exists.. set as current experiment\n",
    "#         facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "#     else:\n",
    "#         print(e)\n",
    "        \n",
    "# print(f\"Setting up Factsheets in {deploy_to}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "364b13f5-d3da-49c6-a07f-6edeace9f425"
   },
   "source": [
    "## Load Train Data and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c31c5352-efa4-40be-b1c0-20a11c092b62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(vars_and_utils.train_data_path)\n",
    "test_data = pd.read_csv(vars_and_utils.test_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f58d554-bb87-4ff4-843a-a496d82110a2"
   },
   "source": [
    "## Load train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "824e8d47-f471-431c-958f-2412802fd91f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_data['Risk']\n",
    "\n",
    "y_test = test_data['Risk']\n",
    "\n",
    "X_train = train_data.drop('Risk',axis=1)\n",
    "\n",
    "X_test = test_data.drop('Risk',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81fae16-dbb4-4d01-b538-b61f71d13c90"
   },
   "source": [
    "## Make validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3af40a2-1e07-4187-bfcb-c12b4b7208cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f79dd02f-22ad-468c-b6a2-235a342c0b48"
   },
   "source": [
    "## Instantiate a Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be29da66-e1b4-4802-94bd-c47255df3f3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_lgb = LGBMClassifier(learning_rate=0.09,max_depth=5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a305e5d9-4750-43f2-8484-85aff909c846"
   },
   "source": [
    "## Append the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "392e164d-948c-49be-adca-1f66b0a72752",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_step = ['model_lgb',model_lgb]\n",
    "pipeline.steps.append(estimator_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80f0fb0b-4131-4357-8bdf-3352f2acab94",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.steps[0][1].fit(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a1f5215-9233-4087-9315-439632632074"
   },
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0119280-a0e5-4e74-92cc-520352a85aba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"starting Model Training. This might take a while\")\n",
    "model_pipeline = pipeline.fit(X_tr,y_tr,model_lgb__verbose=5, model_lgb__eval_set=[(pipeline.steps[0][1].transform(X_val), y_val),(pipeline.steps[0][1].transform(X_tr), y_tr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06f4e2c0-8cf3-4752-8d50-f605014e9756",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import plot_metric\n",
    "plot_metric(pipeline.steps[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a765b3b-46df-4832-998d-f6aa88549744"
   },
   "source": [
    "## Log the Train and Val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae34e2b6-e9fd-401b-b1e2-8de878db2338",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = pipeline.steps[1][1].evals_result_['valid_0']\n",
    "train_loss = pipeline.steps[1][1].evals_result_['valid_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ea87773-790a-48fa-a4b1-5c8134747c9c"
   },
   "source": [
    "## Save train and val loss to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79517f43-a037-418d-88da-e872f5507d8b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss_path = os.path.join(vars_and_utils.data_path, 'val_loss.pkl')\n",
    "vars_and_utils.save_data_in_filesystem(val_loss, val_loss_path)\n",
    "\n",
    "train_loss_path = os.path.join(vars_and_utils.data_path, 'train_loss.pkl')\n",
    "vars_and_utils.save_data_in_filesystem(train_loss, train_loss_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c267c68-d6ab-4283-b157-27791c612f46"
   },
   "source": [
    "## Check if the files are copied in COS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6261ab04-eec2-4ba7-aeba-f4f1b2e0c355",
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_copied_in_cos = os.path.exists(val_loss_path) and os.path.exists(train_loss_path)\n",
    "files_copied_in_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6bb0c1d-b884-4a7a-bd50-e6fb0646be16"
   },
   "source": [
    "## Baseline Results of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7804bdbb-2029-467e-8584-1a15bc90d10b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d51f2fa-4deb-45c8-bad9-3bc489d5d739",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not running_in_production_pipeline:\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scores = np.mean(cross_val_score(pipeline,X_train,y_train, cv=cv, n_jobs=-1,scoring='roc_auc'))\n",
    "    print(f\"The Cross Validated AUC_ROC Score is {scores}\")\n",
    "else:\n",
    "    print(\"Skipping KFold Validation in the production pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a28c746-bd73-4080-933a-9ae887c77b31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(pipeline.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69df87eb-9213-497b-987a-0cb95330e0fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cm = confusion_matrix(y_test,predictions)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in df_cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in df_cm.flatten()/np.sum(df_cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2,v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "try:\n",
    "    sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Seaborn missing, skipping optional heatmap plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b26c707b-15e5-4eb2-8fb8-8badb2f9ceba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print (\"Area Under Curve: %.2f\" %auc(fpr, tpr))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dac2a1f6-84c0-41c3-85ba-8bbdb574fd27"
   },
   "source": [
    "## Serialize Model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ec81eb2-18be-4045-8265-dd57a269e6cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(vars_and_utils.model_path,'wb') as f:\n",
    "    pickle.dump(model_pipeline,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1ebe5c0-e8d9-47ed-94d8-2098f582d2b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skipping for now due to installation issues\n",
    "# cpd_ver = facts_client.get_cpd_version()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16bc9347-e945-4f0d-b108-1a12dd384667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "   \"token\": TOKEN,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n",
    "   \"version\": \"4.6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2bab309-8819-45ab-9baa-c796258c7704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wml_client = APIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b945b0d-2a2a-4415-bb1d-aad42e553958"
   },
   "source": [
    "## Save and Log Models in AI Factsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b814e00a-f777-4fb2-8f8b-58b17f6855c1"
   },
   "outputs": [],
   "source": [
    "# TODO: Rework this without helper scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9341e59f-1bea-4325-9371-e4317034e99e"
   },
   "source": [
    "## Custom succes check: Check if training and test score are above a (very low) threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e6439d9-be5e-4f7e-aa75-77f288b7d100"
   },
   "outputs": [],
   "source": [
    "training_score=pipeline.score(X_train, y_train)\n",
    "test_score=pipeline.score(X_test, y_test)\n",
    "\n",
    "\n",
    "if (training_score>0.7) & (test_score>0.6) & os.path.exists(vars_and_utils.model_path):\n",
    "    training_successful=True\n",
    "else:\n",
    "    training_successful=False\n",
    "\n",
    "training_successful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the output variables for the next pipeine stage\n",
    "every notebook outputs a \"was_successful\" boolean variable. The logic behind this is different for every notebook and can be altered to fit the needs of the project.\n",
    "If needed additional variables can be created here but they also need to registered as output variables in the Watson Pipelines UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ac6de9b-1f91-4e95-a3c2-409c0b065ce6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {}\n",
    "train_params['was_succesfull'] = training_successful\n",
    "\n",
    "\n",
    "pipelines_client = WSPipelines.from_token(TOKEN)\n",
    "pipelines_client.store_results(train_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
