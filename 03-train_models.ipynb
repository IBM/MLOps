{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7db81b2-a955-436b-a4a9-c4e31ff1351e",
    "tags": []
   },
   "source": [
    "## Training Notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5c3939e-aa16-472f-9213-66e415d7f94a"
   },
   "source": [
    "### The following cell is a way to get the utility script required for this notebook. \n",
    "Since IBM CPD SaaS doesn't have a filesystem, this is the only reliable way to get scripts on the cloud environment.\n",
    "\n",
    "```\n",
    "!rm -rf MLOps-CPD && git clone --quiet -b master https://github.com/IBM/MLOps-CPD.git\n",
    "```\n",
    "\n",
    "⚠️ Run the following cells only if you are executing on IBM CPD SaaS.\n",
    "\n",
    "this is a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e06ac24-245a-4dda-aca6-7621038dcacf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!rm -rf MLOps-CPD && git clone --quiet -b master https://github.com/IBM/MLOps-CPD.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a731f27b-724c-4584-85b0-e06215dbacf3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!mv MLOps-CPD MLOps_CPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fc041cf-55e8-4ce4-9ee0-a7f4bac3af11",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "581de62c-b62a-48bf-9105-efac5dd8c45f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install hyperopt ibm_aigov_facts_client ibm_watson_machine_learning ibm_watson_studio_pipelines lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54418317-5b6f-4d8f-8f01-3f8fcb012975",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from ibm_botocore.client import Config\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score,confusion_matrix,plot_confusion_matrix,plot_roc_curve,f1_score,auc,roc_curve,accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from ibm_aigov_facts_client import AIGovFactsClient, CloudPakforDataConfig\n",
    "from ibm_watson_studio_pipelines import WSPipelines\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "import warnings\n",
    "import os, types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ibm_boto3\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os.path import exists\n",
    "if exists(\"utils/fs_utils.py\") and exists(\"utils/catalog_utils.py\"):\n",
    "    from utils import fs_utils,catalog_utils\n",
    "else:\n",
    "    # If utils/fs_utils.py and utils/catalog_utils.py exist we assume that you are running on CPD SaaS\n",
    "    # and will therefore import scripts from the freshly cloned repository\n",
    "    from MLOps_CPD.utils import fs_utils, catalog_utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    import seaborn  as sns\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Optional pluging skipped\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ec9f3a1-7843-4a56-be1f-27321cc488aa"
   },
   "source": [
    "## Pipeline Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "766fc655-4aa3-4967-b341-9c3f19007e0d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## REMOTE AUTH\n",
    "\n",
    "TOKEN = os.getenv(\"USER_ACCESS_TOKEN\")\n",
    "\n",
    "CPD_HOST = os.getenv(\"CPD_HOST\")\n",
    "CPD_USERNAME = os.getenv(\"CPD_USERNAME\")\n",
    "CPD_PASSWORD = os.getenv(\"CPD_PASSWORD\")\n",
    "\n",
    "## LOCAL FS\n",
    "\n",
    "path = os.getenv(\"path\")\n",
    "\n",
    "pipeline_filename = os.getenv(\"pipeline_filename\")\n",
    "\n",
    "train_data_filename = os.getenv(\"train_data_filename\")\n",
    "test_data_filename = os.getenv(\"test_data_filename\")\n",
    "\n",
    "### Construct paths\n",
    "train_data_path = os.path.join(path, train_data_filename)\n",
    "test_data_path = os.path.join(path, test_data_filename)\n",
    "\n",
    "pipeline_path = os.path.join(path, pipeline_filename)\n",
    "\n",
    "## WML / Factsheets\n",
    "\n",
    "EXPERIMENT_NAME = os.getenv(\"EXPERIMENT_NAME\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\")\n",
    "DEPLOYMENT_NAME = os.getenv(\"DEPLOYMENT_NAME\")\n",
    "\n",
    "SPACE_ID = os.getenv(\"SPACE_ID\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e721c290-5509-412a-83ce-573935d14365"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5763f79b-74df-4c2d-9f63-e9a2f9718129",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_for_file_in_filesystem(path):\n",
    "    \"\"\"\n",
    "    Check existence of path in filesystem\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return True\n",
    "    else:\n",
    "        print(\"File not found in specified path.\")\n",
    "        return False     \n",
    "\n",
    "def load_model(key, filename):\n",
    "    check_for_file_in_filesystem(filename)\n",
    "    with open (filename,\"rb\") as f:\n",
    "        pipeline = pickle.load(f)\n",
    "    return pipeline\n",
    "\n",
    "def load_data_from_filesystem(path):\n",
    "    \"\"\"\n",
    "    Check existence of path in filesystem.\n",
    "    If it does exist, loads csv via path\n",
    "    If it does NOT exist, try to load data from Db2\n",
    "    \"\"\"\n",
    "    body = check_for_file_in_filesystem(path)\n",
    "    if body:\n",
    "        suffix = path[-3:]\n",
    "        # Check whether path ends on csv\n",
    "        if suffix == \"csv\":\n",
    "            gcf_df = pd.read_csv(path)\n",
    "        else:\n",
    "            with open(path) as f:\n",
    "                gcf_df = pickle.load(f)\n",
    "\n",
    "        return gcf_df\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(f\"{path} file/path is probably not in project. Loading File from MLOps COS Bucket.\")\n",
    "\n",
    "        data_request = {\n",
    "                'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "                'interaction_properties': {\n",
    "                    'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "                }\n",
    "            }\n",
    "\n",
    "        gcf_df = read_data_from_db2(data_request)\n",
    "        return gcf_df\n",
    "\n",
    "\n",
    "def read_data_from_db2(data_request):\n",
    "    \"\"\"\n",
    "    \n",
    "    If load_data_from_filesystem fails, this method is executed.\n",
    "    \"\"\"\n",
    "    read_client = itcfs.get_flight_client()\n",
    "    DB2_DATA_data_request = {\n",
    "        'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "        'interaction_properties': {\n",
    "            'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    flightInfo = itcfs.get_flight_info(read_client, nb_data_request=data_request)\n",
    "\n",
    "    df = itcfs.read_pandas_and_concat(read_client, flightInfo, timeout=240)\n",
    "    return df\n",
    "\n",
    "def save_data_in_filesystem(df,filename):\n",
    "    \"\"\"\n",
    "    Save Data in Filesystem\n",
    "\n",
    "    Passed filename should involve path\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if filename[-3:] == \"csv\":\n",
    "            df.to_csv(filename,index=False)\n",
    "            print(f\"File {filename} persisted successfully as csv\")\n",
    "        else:\n",
    "            with open(filename, 'wb') as f:\n",
    "                pickle.dump(df, f)\n",
    "            print(f\"File {filename} pickled successfully\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"File serialization for {filename} failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "189ac0c4-ddf1-4e51-b4f2-8478c1d8d4f2"
   },
   "source": [
    "## Load the Saved Transformer from IBM COS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97a6f8fa-3fa3-4310-84f7-435a544fdb42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = load_model(pipeline_path, pipeline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22fd1435-a5a1-430a-8347-96498617dc05"
   },
   "source": [
    "## Instantiate FactSheets Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "601c230e-8608-46a4-a84b-d8c522fa699f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set-up Factsheets\n",
    "cpd_creds = CloudPakforDataConfig(service_url=CPD_HOST, username=CPD_USERNAME, password=CPD_PASSWORD)\n",
    "    \n",
    "if SPACE_ID is None:\n",
    "    # Only of SPACE_ID is unavailble, fallback to PROJECT_ID\n",
    "    if PROJECT_ID is None:\n",
    "        # Neither SPACE_ID nor PROJECT_ID available\n",
    "        pass\n",
    "    else:\n",
    "        # PROJECT_ID available\n",
    "        deploy_to = 'project'\n",
    "        try:\n",
    "            # Create new experiment\n",
    "            facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "        except Exception as e:\n",
    "            # Experiment already exists.. set as current experiment\n",
    "            facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=PROJECT_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "        else:\n",
    "            print(e)\n",
    "else:\n",
    "    # SPACE_ID is available\n",
    "    deploy_to = 'space'\n",
    "    try:\n",
    "        # Create new experiment\n",
    "        facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds)\n",
    "    except Exception as e:\n",
    "        # Experiment already exists.. set as current experiment\n",
    "        facts_client = AIGovFactsClient(experiment_name=EXPERIMENT_NAME,container_type=deploy_to,container_id=SPACE_ID,cloud_pak_for_data_configs=cpd_creds,set_as_current_experiment=True)\n",
    "    else:\n",
    "        print(e)\n",
    "        \n",
    "print(f\"Setting up Factsheets in {deploy_to}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "364b13f5-d3da-49c6-a07f-6edeace9f425"
   },
   "source": [
    "## Load Train Data and Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c31c5352-efa4-40be-b1c0-20a11c092b62",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = load_data_from_filesystem(train_data_path)\n",
    "test_data = load_data_from_filesystem(test_data_path)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f58d554-bb87-4ff4-843a-a496d82110a2"
   },
   "source": [
    "## Load train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "824e8d47-f471-431c-958f-2412802fd91f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = train_data['Risk']\n",
    "\n",
    "y_test = test_data['Risk']\n",
    "\n",
    "X_train = train_data.drop('Risk',axis=1)\n",
    "\n",
    "X_test = test_data.drop('Risk',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e81fae16-dbb4-4d01-b538-b61f71d13c90"
   },
   "source": [
    "## Make validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3af40a2-1e07-4187-bfcb-c12b4b7208cc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f79dd02f-22ad-468c-b6a2-235a342c0b48"
   },
   "source": [
    "## Instantiate a Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be29da66-e1b4-4802-94bd-c47255df3f3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "model_lgb = LGBMClassifier(learning_rate=0.09,max_depth=5,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a305e5d9-4750-43f2-8484-85aff909c846"
   },
   "source": [
    "## Append the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "392e164d-948c-49be-adca-1f66b0a72752",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator_step = ['model_lgb',model_lgb]\n",
    "pipeline.steps.append(estimator_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80f0fb0b-4131-4357-8bdf-3352f2acab94",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.steps[0][1].fit(X_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a1f5215-9233-4087-9315-439632632074"
   },
   "source": [
    "## Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0119280-a0e5-4e74-92cc-520352a85aba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_pipeline = pipeline.fit(X_train,y_train)\n",
    "model_pipeline = pipeline.fit(X_tr,y_tr,model_lgb__verbose=5, model_lgb__eval_set=[(pipeline.steps[0][1].transform(X_val), y_val),(pipeline.steps[0][1].transform(X_tr), y_tr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06f4e2c0-8cf3-4752-8d50-f605014e9756",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lightgbm import plot_metric\n",
    "plot_metric(pipeline.steps[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a765b3b-46df-4832-998d-f6aa88549744"
   },
   "source": [
    "## Log the Train and Val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ae34e2b6-e9fd-401b-b1e2-8de878db2338",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss = pipeline.steps[1][1].evals_result_['valid_0']\n",
    "train_loss = pipeline.steps[1][1].evals_result_['valid_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ea87773-790a-48fa-a4b1-5c8134747c9c"
   },
   "source": [
    "## Save train and val loss to COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79517f43-a037-418d-88da-e872f5507d8b",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loss_path = os.path.join(path, 'val_loss.pkl')\n",
    "save_data_in_filesystem(val_loss, val_loss_path)\n",
    "\n",
    "train_loss_path = os.path.join(path, 'train_loss.pkl')\n",
    "save_data_in_filesystem(train_loss, train_loss_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c267c68-d6ab-4283-b157-27791c612f46"
   },
   "source": [
    "## Check if the files are copied in COS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6261ab04-eec2-4ba7-aeba-f4f1b2e0c355",
    "tags": []
   },
   "outputs": [],
   "source": [
    "files_copied_in_cos = check_for_file_in_filesystem(val_loss_path) and check_for_file_in_filesystem(train_loss_path)\n",
    "files_copied_in_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6bb0c1d-b884-4a7a-bd50-e6fb0646be16"
   },
   "source": [
    "## Baseline Results of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7804bdbb-2029-467e-8584-1a15bc90d10b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "print(roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d51f2fa-4deb-45c8-bad9-3bc489d5d739",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "scores = np.mean(cross_val_score(pipeline,X_train,y_train, cv=cv, n_jobs=-1,scoring='roc_auc'))\n",
    "print(f\"The Cross Validated AUC_ROC Score is {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a28c746-bd73-4080-933a-9ae887c77b31",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(pipeline.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69df87eb-9213-497b-987a-0cb95330e0fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_cm = confusion_matrix(y_test,predictions)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in df_cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in df_cm.flatten()/np.sum(df_cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2,v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "try:\n",
    "    sns.heatmap(df_cm, annot=labels, fmt='', cmap='Blues')\n",
    "except Exception as e:\n",
    "    print(str(e) + \" - Seaborn missing, skipping optional heatmap plot.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b26c707b-15e5-4eb2-8fb8-8badb2f9ceba",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], transform=ax.transAxes, ls=\"--\", c=\".3\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)\n",
    "\n",
    "print(\"\\n\")\n",
    "print (\"Area Under Curve: %.2f\" %auc(fpr, tpr))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dac2a1f6-84c0-41c3-85ba-8bbdb574fd27"
   },
   "source": [
    "## Serialize Model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cbca9b7-f56f-4fef-98d7-dc9977ec9487",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(path, MODEL_NAME+\".pkl\")\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ec81eb2-18be-4045-8265-dd57a269e6cb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(model_path,'wb') as f:\n",
    "    pickle.dump(model_pipeline,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1ebe5c0-e8d9-47ed-94d8-2098f582d2b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpd_ver = facts_client.get_cpd_version()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16bc9347-e945-4f0d-b108-1a12dd384667",
    "tags": []
   },
   "outputs": [],
   "source": [
    "WML_CREDENTIALS = {\n",
    "   \"token\": TOKEN,\n",
    "   \"instance_id\" : \"openshift\",\n",
    "   \"url\": os.environ['RUNTIME_ENV_APSX_URL'],\n",
    "   \"version\": \"4.6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2bab309-8819-45ab-9baa-c796258c7704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "wml_client = APIClient(WML_CREDENTIALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b945b0d-2a2a-4415-bb1d-aad42e553958"
   },
   "source": [
    "## Save and Log Models in AI Factsheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b814e00a-f777-4fb2-8f8b-58b17f6855c1"
   },
   "outputs": [],
   "source": [
    "# TODO: Rework this without helper scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9341e59f-1bea-4325-9371-e4317034e99e"
   },
   "source": [
    "## Save Params in WS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ac6de9b-1f91-4e95-a3c2-409c0b065ce6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {}\n",
    "train_params['auc_roc'] = float(auc(fpr, tpr))\n",
    "train_params['training_done'] = True\n",
    "train_params['model_name'] = MODEL_NAME\n",
    "train_params['model_path'] = model_path\n",
    "train_params['deployment_name'] = DEPLOYMENT_NAME\n",
    "# train_params['model_id'] = model_id\n",
    "train_params['project_id'] = project_id if not None else None\n",
    "# train_params['model_pipeline'] = \"/home/wsuser/work/model_pipeline.pkl\"\n",
    "\n",
    "pipelines_client = WSPipelines.from_token(TOKEN)\n",
    "pipelines_client.store_results(train_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
