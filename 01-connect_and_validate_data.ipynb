{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9501e8a8-d435-4451-a8ae-513e984aafe9"
   },
   "source": [
    "## Connection and Data Validation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b64a45cb-07f3-4a20-a863-6a17d9fb17c9"
   },
   "source": [
    "## Table of Contents\n",
    "* [Check for Training Data in Project Space](#DataCheck)\n",
    "    * [Load the Training Data from Db2 if it does not exist in the project space](#section_1_1)\n",
    "    \n",
    "    * [Check the connection and data loading](#section_1_2)\n",
    "  \n",
    "* [Data Validation](#chapter2)\n",
    "    * [Split the Data](#Optional)\n",
    "\n",
    "    * [Generate Training Stats on both Splits](#section_2_2)\n",
    "    * [Infer Schema on both Splits](#section_2_3) \n",
    "    * [Check for anomalies](#section_2_4) \n",
    "    * [Return a boolean to validate the tests](#section_3_1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1f3c063-b384-4b66-8087-854e8e76d88c"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fe00539c-a0ab-4769-ba7b-805adea59cf8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.client import Config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import itc_utils.flight_service as itcfs\n",
    "\n",
    "\n",
    "# TODO: Await (or build) for py3.10 version\n",
    "# import tensorflow_data_validation as tfdv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ibm_watson_studio_pipelines import WSPipelines\n",
    "import ibm_boto3\n",
    "\n",
    "import logging\n",
    "import os, types\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "062a2e71-ddbf-4c77-aaeb-d5aa7ac8d265"
   },
   "source": [
    "### Load the Credentials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63ab6462-e420-4aea-93ee-4e0b80de3c9e"
   },
   "source": [
    "These environment variables are set in WS Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e875ff36-3235-43fb-8008-4bfb334c1325",
    "tags": []
   },
   "outputs": [],
   "source": [
    "TOKEN = os.getenv(\"USER_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8fed6b28-77f7-4230-ba5e-b7d43e8a55ec",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Expects existing path and existing training_file_name within that path\n",
    "training_file_name = os.getenv(\"training_file_name\")\n",
    "path = os.getenv(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "665c7cd8-2611-4fea-b679-f47b7b293d7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_file_name = \"german_credit_data_biased_training.csv\"\n",
    "path = \"mlops-dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1b343151-c20f-41ba-b7b2-6cea3e9ca42a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_file_path = os.path.join(path, training_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0d25efd1-cabd-4721-bb9d-461875a977db"
   },
   "source": [
    "## Check for Training Data in Project Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "b249d03b-a811-4624-9f71-003991cb1832",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_for_file_in_filesystem(path):\n",
    "    if os.path.exists(path):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def read_data_from_db2(data_request):\n",
    "    read_client = itcfs.get_flight_client()\n",
    "    DB2_DATA_data_request = {\n",
    "        'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "        'interaction_properties': {\n",
    "            'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    flightInfo = itcfs.get_flight_info(read_client, nb_data_request=data_request)\n",
    "\n",
    "    df = itcfs.read_pandas_and_concat(read_client, flightInfo, timeout=240)\n",
    "    return df\n",
    "    \n",
    "def load_data_from_project(path):\n",
    "    body = check_for_file_in_filesystem(path)\n",
    "    if body:\n",
    "        gcf_df = pd.read_csv(path)\n",
    "        return gcf_df\n",
    "    else:\n",
    "        print(\"\\n\")\n",
    "        print(f\"{path} file/path is probably not in project. Loading File from MLOps COS Bucket.\")\n",
    "\n",
    "        data_request = {\n",
    "                'connection_name': \"\"\"DB2_DATA\"\"\",\n",
    "                'interaction_properties': {\n",
    "                    'select_statement': 'SELECT * FROM \"CUSTOMER_DATA\".\"GERMAN_CREDIT_RISK_TRAINING\" FETCH FIRST 5000 ROWS ONLY'\n",
    "                }\n",
    "            }\n",
    "\n",
    "        gcf_df = read_data_from_db2(data_request)\n",
    "        return gcf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d44e72ca-25cf-44c2-a8f4-4ad6eff50e4a"
   },
   "source": [
    "## Load the Training Data from Db2 if the file doesn't exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0487c397-3d75-4292-ae6f-8f2cd4bb8f19",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CheckingStatus</th>\n",
       "      <th>LoanDuration</th>\n",
       "      <th>CreditHistory</th>\n",
       "      <th>LoanPurpose</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>ExistingSavings</th>\n",
       "      <th>EmploymentDuration</th>\n",
       "      <th>InstallmentPercent</th>\n",
       "      <th>Sex</th>\n",
       "      <th>OthersOnLoan</th>\n",
       "      <th>...</th>\n",
       "      <th>OwnsProperty</th>\n",
       "      <th>Age</th>\n",
       "      <th>InstallmentPlans</th>\n",
       "      <th>Housing</th>\n",
       "      <th>ExistingCreditsCount</th>\n",
       "      <th>Job</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Telephone</th>\n",
       "      <th>ForeignWorker</th>\n",
       "      <th>Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_to_200</td>\n",
       "      <td>31</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>other</td>\n",
       "      <td>1889</td>\n",
       "      <td>100_to_500</td>\n",
       "      <td>less_1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>32</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>less_0</td>\n",
       "      <td>18</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>car_new</td>\n",
       "      <td>462</td>\n",
       "      <td>less_100</td>\n",
       "      <td>1_to_4</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>37</td>\n",
       "      <td>stores</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>less_0</td>\n",
       "      <td>15</td>\n",
       "      <td>prior_payments_delayed</td>\n",
       "      <td>furniture</td>\n",
       "      <td>250</td>\n",
       "      <td>less_100</td>\n",
       "      <td>1_to_4</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real_estate</td>\n",
       "      <td>28</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_to_200</td>\n",
       "      <td>28</td>\n",
       "      <td>credits_paid_to_date</td>\n",
       "      <td>retraining</td>\n",
       "      <td>3693</td>\n",
       "      <td>less_100</td>\n",
       "      <td>greater_7</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>savings_insurance</td>\n",
       "      <td>32</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no_checking</td>\n",
       "      <td>28</td>\n",
       "      <td>prior_payments_delayed</td>\n",
       "      <td>education</td>\n",
       "      <td>6235</td>\n",
       "      <td>500_to_1000</td>\n",
       "      <td>greater_7</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>57</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CheckingStatus  LoanDuration           CreditHistory LoanPurpose  \\\n",
       "0       0_to_200            31    credits_paid_to_date       other   \n",
       "1         less_0            18    credits_paid_to_date     car_new   \n",
       "2         less_0            15  prior_payments_delayed   furniture   \n",
       "3       0_to_200            28    credits_paid_to_date  retraining   \n",
       "4    no_checking            28  prior_payments_delayed   education   \n",
       "\n",
       "   LoanAmount ExistingSavings EmploymentDuration  InstallmentPercent     Sex  \\\n",
       "0        1889      100_to_500             less_1                   3  female   \n",
       "1         462        less_100             1_to_4                   2  female   \n",
       "2         250        less_100             1_to_4                   2    male   \n",
       "3        3693        less_100          greater_7                   3    male   \n",
       "4        6235     500_to_1000          greater_7                   3    male   \n",
       "\n",
       "  OthersOnLoan  ...       OwnsProperty Age  InstallmentPlans Housing  \\\n",
       "0         none  ...  savings_insurance  32              none     own   \n",
       "1         none  ...  savings_insurance  37            stores     own   \n",
       "2         none  ...        real_estate  28              none     own   \n",
       "3         none  ...  savings_insurance  32              none     own   \n",
       "4         none  ...            unknown  57              none     own   \n",
       "\n",
       "  ExistingCreditsCount      Job Dependents  Telephone ForeignWorker Risk  \n",
       "0                    1  skilled          1       none           yes    0  \n",
       "1                    2  skilled          1       none           yes    0  \n",
       "2                    2  skilled          1        yes            no    0  \n",
       "3                    1  skilled          1       none           yes    0  \n",
       "4                    2  skilled          1       none           yes    1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcr_df = load_data_from_project(training_file_path)\n",
    "\n",
    "## Encode for ease of use with OpenScale\n",
    "gcr_df['Risk'] = gcr_df['Risk'].map({'Risk':1,'No Risk':0})\n",
    "gcr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e38d5859-3df7-4174-8f8c-a047c0dcdb3c"
   },
   "source": [
    "## Data Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "37d30747-1f1d-42ad-ab50-6001740df627",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Datavalidation:\n",
    "    \"\"\"\n",
    "    \n",
    "    Data Validation Class\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe : pd.DataFrame\n",
    "    mask_per :int\n",
    "    \n",
    "    \n",
    "    def split_data(self,seed=32):\n",
    "        \"\"\"\n",
    "        Split Data into Train and Test Splits\n",
    "        \n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        mask = np.random.rand(len(self.dataframe)) <= self.mask_per\n",
    "        training_data = gcr_df[mask]\n",
    "        testing_data = gcr_df[~mask]\n",
    "\n",
    "        print(f\"No. of training examples: {training_data.shape[0]}\")\n",
    "        print(f\"No. of testing examples: {testing_data.shape[0]}\")\n",
    "        \n",
    "        return training_data, testing_data\n",
    "    \n",
    "    # TODO: Replace with Db2/fileystem\n",
    "    def save_data_in_filesystem(self,df,filename):\n",
    "        \"\"\"\n",
    "        Save Data in Filesystem\n",
    "\n",
    "        Passed filename should involve path\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df.to_csv(filename,index=False)\n",
    "            print(f\"File {filename} persisted successfully\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"File serialization for {filename} failed\")\n",
    "    \n",
    "    def generate_statistics(self,df):\n",
    "        \"\"\"\n",
    "        \n",
    "        Generate Statistics on a given Dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        train_stats = tfdv.generate_statistics_from_dataframe(df)\n",
    "        tfdv.visualize_statistics(train_stats)\n",
    "        return train_stats\n",
    "    \n",
    "    def inferSchema(self,stats):\n",
    "        \n",
    "        \"\"\"\n",
    "        InferSchema on a given Dataframe\n",
    "        \n",
    "        \"\"\"\n",
    "        schema = tfdv.infer_schema(statistics=stats)\n",
    "        tfdv.display_schema(schema=schema)\n",
    "        return schema\n",
    "    \n",
    "    def compare_statistics(self,lhs,rhs):\n",
    "        \"\"\"\n",
    "        \n",
    "        Compare Statistics between a test dataframe and reference Schema\n",
    "        \n",
    "        \"\"\"\n",
    "        # Compare evaluation data with training data\n",
    "        tfdv.visualize_statistics(lhs_statistics=lhs, rhs_statistics=rhs,\n",
    "                                  lhs_name='TEST_DATASET', rhs_name='TRAIN_DATASET')\n",
    "        \n",
    "        \n",
    "    def check_for_anomalies(self,testable_stats,ref_schema):\n",
    "        \"\"\"\n",
    "        \n",
    "        Check for any anomalies based on statistics and schema and values\n",
    "        \n",
    "        \"\"\"\n",
    "        anomalies = tfdv.validate_statistics(statistics=testable_stats, schema=ref_schema)\n",
    "        tfdv.display_anomalies(anomalies)\n",
    "        if len(anomalies.anomaly_info.items()) > 0:\n",
    "            logger.error(\"Anomalies found in dataset...\")\n",
    "            logger.error(str(self.anomalies.anomaly_info.items()))\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fff2bb05-abd0-4e0a-9727-d1127a617f57"
   },
   "source": [
    "###  Split Data into Train and Eval Splits to Check for Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "65163ff9-3193-4837-ab55-d66de3a5076f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training examples: 3995\n",
      "No. of testing examples: 1005\n"
     ]
    }
   ],
   "source": [
    "classvalidate = Datavalidation(dataframe=gcr_df,mask_per=0.8) \n",
    "\n",
    "training_data, testing_data = classvalidate.split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75029b2c-6341-4a59-957c-cbb2d33e3e39"
   },
   "source": [
    "## Generate Training Stats on both Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "36a97f3f-3cd7-493d-8a4b-c3c87ae0710f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfdv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mclassvalidate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_statistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mDatavalidation.generate_statistics\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_statistics\u001b[39m(\u001b[38;5;28mself\u001b[39m,df):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m    Generate Statistics on a given Dataframe\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtfdv\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate_statistics_from_dataframe(df)\n\u001b[1;32m     49\u001b[0m     tfdv\u001b[38;5;241m.\u001b[39mvisualize_statistics(train_stats)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_stats\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfdv' is not defined"
     ]
    }
   ],
   "source": [
    "train_stats = classvalidate.generate_statistics(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "020788e5-00ba-4779-bdb7-398445bfb7fc"
   },
   "outputs": [],
   "source": [
    "test_stats = classvalidate.generate_statistics(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed4d3f56-e852-4269-a3dd-8426d71bed8e"
   },
   "source": [
    "## Infer Training Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13f7be93-3fb1-49ca-9238-ebb1fcc1af28"
   },
   "outputs": [],
   "source": [
    "train_schema = classvalidate.inferSchema(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e79f56a-29b6-4c80-a201-16fe5eb5a245"
   },
   "source": [
    "## Infer Test Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ce74ad2-9ec9-48f3-959a-f0b59b077706"
   },
   "outputs": [],
   "source": [
    "test_schema = classvalidate.inferSchema(test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ea9f07ac-ac4b-4ecd-8840-a5ab07bfb7f8"
   },
   "source": [
    "## Compare Eval and Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5ccfb5d-05bd-4b3b-9f4d-8082252457c3"
   },
   "outputs": [],
   "source": [
    "classvalidate.compare_statistics(lhs=test_stats,rhs=train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "915f6a20-aab3-47b5-86e9-93bde2f548ff"
   },
   "source": [
    "## Check For Data Anomalies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eae32b5f-46b3-4e5d-919e-68c206a47b8e"
   },
   "source": [
    "### Check eval data for errors by validating the eval data stats using the previously inferred schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2927d8b-fa0f-420f-9181-a080cdfcb748"
   },
   "outputs": [],
   "source": [
    "anomaly_status = classvalidate.check_for_anomalies(test_stats,train_schema)\n",
    "anomaly_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c914eade-25d9-497a-960e-ec5a57282def"
   },
   "source": [
    "## Save Train and Test Data for Data Preparation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7e508e03-07c4-4a22-bdba-dc8fc400eca8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_filename = \"train_gcr.csv\"\n",
    "test_data_filename = \"test_gcr.csv\"\n",
    "train_data_path = os.path.join(path, train_data_filename)\n",
    "test_data_path = os.path.join(path, test_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2b0d34de-d26e-460b-8bbd-66c4cf603e2b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "anomaly_status = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0f1d08cc-e4f7-4010-8b4e-7414529e874a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File mlops-dir/train_gcr.csv persisted successfully\n",
      "File mlops-dir/test_gcr.csv persisted successfully\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace with Db2/fileystem\n",
    "if not anomaly_status:\n",
    "    classvalidate.save_data_in_filesystem(df=training_data,filename=train_data_path)\n",
    "    classvalidate.save_data_in_filesystem(df=testing_data,filename=test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ed16fe2-48e7-4afc-8cb5-562e90079303"
   },
   "source": [
    "## Check if files Exists in COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25d715cf-f7b2-4106-9259-0f1a5762710a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Replace with Db2/fileystem\n",
    "files_copied_in_cos = check_for_file_in_filesystem(train_data_path) and check_for_file_in_filesystem(test_data_path)\n",
    "files_copied_in_cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b42568a9-36f8-407e-be7a-f8bbbf93444a"
   },
   "source": [
    "## Register a Boolean Variable in WS Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f210efd-7358-41a4-9ab5-37a856f3ab47",
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_params = {}\n",
    "validation_params['anomaly_status'] = anomaly_status\n",
    "validation_params['files_copied_in_cos'] = files_copied_in_cos\n",
    "validation_params['train_data_filename'] = train_data_filename\n",
    "validation_params['test_data_filename'] = test_data_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bf0ff093-af79-4bb5-bd22-d2d5315926e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running outside of Watson Studio Pipeline - storing results in the local filesystem for testing purposes...\n",
      "\n",
      "  output paths:\n",
      "    - \"anomaly_status\": .ibm_watson_studio_pipelines/results/anomaly_status\n",
      "    - \"files_copied_in_cos\": .ibm_watson_studio_pipelines/results/files_copied_in_cos\n",
      "    - \"train_data_path\": .ibm_watson_studio_pipelines/results/train_data_path\n",
      "    - \"test_data_path\": .ibm_watson_studio_pipelines/results/test_data_path\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ibm_cloud_sdk_core.detailed_response.DetailedResponse at 0x7f2cd1419a80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipelines_client = WSPipelines.from_token(token=TOKEN)\n",
    "pipelines_client = WSPipelines.from_token(TOKEN)\n",
    "pipelines_client.store_results(validation_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
